Работа локально на Linux — это идеальный сценарий, потому что здесь у тебя есть полный контроль над файловой системой и процессами. Тебе не нужно воевать с изоляцией виртуалок GitHub.

Вот как реализовать «всевидящее око» для LLM, сохраняя при этом раздельные терминалы, разные сессии Telepresence и независимый дебаг в каждом репозитории.

1. Метод «Symlink Mirror» (Самый эффективный)
Поскольку все твои 10+ репозиториев уже лежат на одном диске (например, в ~/projects/), тебе достаточно сделать их видимыми друг для друга.

Что сделать:
Внутри репозитория mentor-api создай скрытую папку .system-context и наполни её символическими ссылками на соседние репозитории.

Bash
# Находясь в ~/projects/mentor-api
mkdir -p .system-context
ln -s ~/projects/charts ./.system-context/charts
ln -s ~/projects/infra ./.system-context/infra
# Добавь это в .gitignore, чтобы не засорять репозиторий
echo ".system-context/" >> .gitignore
Результат:

Для тебя: Ты продолжаешь работать в двух разных окнах терминала/IDE. В одном окне у тебя mentor-api с его дебагом, в другом — charts.

Для LLM в mentor-api: Она видит папку .system-context/charts как часть текущего проекта. Она может читать шаблоны, править их и анализировать.

Синхронизация: Поскольку это симлинка, любые правки, которые LLM сделает в .system-context/charts/file.yaml, мгновенно отобразятся в твоем втором окне, где открыт оригинальный charts. Тебе останется только нажать «Save» и «Commit».

2. Multi-Root Workspace (VS Code / Cursor / Roo Code)
Это «Best Practice» для локальной разработки. Вместо того чтобы открывать 10 разных окон IDE, ты открываешь одно окно, но добавляешь в него все нужные папки.

Открой mentor-api.

File > Add Folder to Workspace... -> выбери charts, infra и т.д.

Сохрани воркспейс как mathtrail.code-workspace.

Почему это решает твою проблему:

Контекст: LLM (например, расширение Roo Code или Cursor) индексирует весь воркспейс. Она видит связи между кодом в одном проекте и конфигом в другом.

Изоляция дебага: В VS Code для каждой папки воркспейса можно настроить свой launch.json. Ты можешь запустить дебаг mentor-api в одном процессе, а Telepresence для другого сервиса — в другом, оставаясь в рамках одного окна IDE.

Терминалы: Ты можешь открыть несколько терминалов внизу и привязать каждый к своей папке.

3. Настройка CLAUDE.md для локальной среды
Чтобы LLM не боялась выходить за пределы текущей папки, добавь в CLAUDE.md (или .clauderules) следующее:

Markdown
## Environment Context
- I am working on a Linux machine. All microservices are located in `../`.
- You have permission to access neighbor directories for context or direct edits.
- Key reference paths:
  - Charts: `../charts`
  - Infra: `../infra`
- If you need to modify a Helm chart while working on Mentor API, do it directly in `../charts`.
4. Почему это лучше, чем в Codespaces?
Мгновенность: Никаких сетевых задержек (NFS/SSHFS). Файлы меняются атомарно.

Shared Tools: Все твои локальные инструменты (Telepresence, kubectl, just, go) доступны всем инстансам LLM одновременно.

Единый кэш: Если ты используешь локальный LLM-сервер (например, Ollama) или индексатор, он будет использовать общую память для всех проектов.

Итог: Мой совет
Если ты работаешь локально, не плоди сущности.

Используй Multi-Root Workspace в VS Code. Это даст LLM общую видимость.

Разнеси терминалы по разным вкладкам внутри VS Code (один для дебага API, другой для Telepresence инфраструктуры).

В CLAUDE.md пропиши относительные пути ../charts.

Это позволит тебе сказать Claude: "Слушай, я тут в mentor-api меняю структуру секретов, сходи в ../charts/templates и поправь там vault-job, чтобы всё не развалилось". И она это сделает.

Хочешь, я помогу составить структуру justfile, который будет управлять командами сразу во всех этих папках, чтобы тебе было удобнее переключаться?