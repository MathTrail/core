ТЗ для Claude: Внедрение Apache Flink в экосистему MathTrail
Контекст:
Мы реализуем слой Stream Processing для образовательной платформы MathTrail. Наша цель — обеспечить реактивное обогащение данных и заложить фундамент для последующего внедрения Real-time AI (анализ поведения ученика). В качестве основного движка обработки выбран Apache Flink, так как он обеспечивает максимальную гибкость и поддержку Exactly-once семантики.

Задача:

Инфраструктура: Развернуть Flink Kubernetes Operator.

GitOps: Скачать необходимые Helm-чарты в локальный репозиторий mathtrail-charts.

Архитектура: Описать и визуализировать сквозной поток данных.

Observability: Настроить экспорт телеметрии в существующий стек LGTM через OpenTelemetry Collector.

Детальные требования:
1. Управление чартами (GitOps)
Скачай официальный Helm-чарт для Flink Kubernetes Operator.

Размести его в директории mathtrail-charts/flink-operator.

Подготовь values.yaml: настрой ресурсы и убедись, что оператор готов к работе в высоконагруженном режиме.

2. Документация и визуализация
Создай файл mathtrail/docs/architecture/stream-processing.md.

Добавь Mermaid-диаграмму, описывающую полный путь события:
Microservice (Writer) -> Postgres (WAL) -> Debezium Connector -> Kafka (Source Topics) -> Flink Job (Enrichment) -> Kafka (Enriched Topics) -> Microservices (Consumers).

Отрази на схеме взаимодействие с Apicurio Schema Registry для контроля контрактов данных.

3. Конфигурация FlinkDeployment (Ferrari Setup)
Создай манифест FlinkDeployment для сервиса обогащения:

State Backend: Используй RocksDB для работы с большими состояниями (миллионы профилей).

Storage: Настрой PersistentVolume для хранения инкрементальных чекпоинтов.

Exactly-Once: Включи чекпоинты (раз в 1 минуту) для гарантии целостности данных.

4. Интеграция с Observability (OpenTelemetry)
Это критический пункт. Настрой Flink так, чтобы он вписался в наш стек:

Metrics: Сконфигурируй OpenTelemetry Metric Reporter во Flink, чтобы он отправлял метрики (lag, throughput, CPU/RAM) в наш OpenTelemetry Collector.

Logging: Настроил логирование в формате JSON для корректного сбора в Grafana Loki.

Tracing: Учти возможность проброса Trace ID через Kafka заголовки, чтобы мы видели сквозной путь события от записи в Postgres до обработки во Flink (в связке с Dapr).

5. Реализация логики (Flink SQL)
Подготовь пример FlinkDeployment, использующий Flink SQL Gateway или YAML-определение Job:

Опиши TEMPORARY TABLE для Kafka топиков с использованием avro-confluent.

Реализуй JOIN между основным потоком событий и таблицами-справочниками.

Настрой запись результата в результирующий топик.